{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.min_rows\", 50)\n",
    "pd.set_option(\"display.precision\", 8)\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import joblib \n",
    "import json\n",
    "import time\n",
    "from tableone import TableOne\n",
    "from scipy import sparse\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "data_dir ='./data'\n",
    "basedir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import clinprediction.omop_fx\n",
    "importlib.reload(clinprediction.omop_fx)\n",
    "\n",
    "import clinprediction.patient_fx\n",
    "importlib.reload(clinprediction.patient_fx)\n",
    "\n",
    "import clinprediction.match_fx\n",
    "importlib.reload(clinprediction.match_fx)\n",
    "\n",
    "import clinprediction.model_fx\n",
    "importlib.reload(clinprediction.match_fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_options = ['testdate','AD','control'] \n",
    "in_dir = basedir + 'data/'\n",
    "pdir = basedir + 'cohort_selection/'\n",
    "output_dir = basedir + 'cohort_selection_out/'\n",
    "\n",
    "if load_options is not None:\n",
    "    options = load_in_options(*load_options)\n",
    "    odir_main = options['odir_main']\n",
    "    demo_cols = options['demo_cols']\n",
    "    cols_match_num = options['match_params']['cols_match_num']\n",
    "    cols_match_vis = options['match_params']['cols_match_vis']\n",
    "    cols_match_cat = options['match_params']['cols_match_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinspokeprediction.omop_fx import OMOPData\n",
    "\n",
    "start = time.time()\n",
    "omopdata = OMOPData(omopdir = 'data/omop/')\n",
    "\n",
    "# Read in OMOP information for patients of interest.\n",
    "try: \n",
    "    omopdata.load_compressed(pdir)\n",
    "except: \n",
    "    omopdata.read_in_omop_csv(directory = pdir, read_in_controls = True)\n",
    "    omopdata.save_compressed()\n",
    "    \n",
    "# Concept look-up dictionary\n",
    "conceptdict = omopdata.concepts.set_index('concept_id')['concept_name'].to_dict()\n",
    "\n",
    "print(omopdata.size_of_data_col('iscontrol'))\n",
    "print('Finished reading in OMOP data. took {} minutes'.format((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in patients\n",
    "from clinspokeprediction.patient_fx import read_in_patients, age_visit_timefilt, filter_pts\n",
    "from clinspokeprediction.match_fx import match_patients\n",
    "\n",
    "timefilt_min = np.array(options['timefilt_range']).min()\n",
    "\n",
    "if 'allpts_timefiltmin_file' in options:\n",
    "    allpts = pd.read_csv(options['allpts_timefiltmin_file'])\n",
    "else: \n",
    "    raise Exception('Run 2_predictAD.ipynb first')\n",
    "    \n",
    "person_id_train = np.load(options['person_id_train_all_file'])\n",
    "person_id_test = np.load(options['person_id_test_all_file'])\n",
    "print('train number pid:', len(person_id_train))\n",
    "print('test number pid:', len(person_id_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from clinspokeprediction.omop_fx import filter_omopdata_by_time\n",
    "for timefilt in options['timefilt_range']:\n",
    "    odir_tf = options['odir_main'] + str(timefilt) + '/'\n",
    "    os.makedirs(odir_tf, exist_ok = True)\n",
    "\n",
    "    print(odir_tf + 'omop_count_demo_visit.joblib exists.')\n",
    "    print('getting information at timefilt:{}'.format(timefilt))\n",
    "    omop_pt_tf_input = joblib.load(odir_tf + 'omop_count_demo_visit.joblib')\n",
    "    allpt_tf = omop_pt_tf_input['allpt_tf']\n",
    "    allpt_tf_train = omop_pt_tf_input['allpt_tf_train'] \n",
    "    allpt_tf_test = omop_pt_tf_input['allpt_tf_test']\n",
    "    pts_train_tf = omop_pt_tf_input['train_pts']\n",
    "    pts_test_tf = omop_pt_tf_input['test_pts']\n",
    "    feat_concepts = omop_pt_tf_input['feat_concepts']\n",
    "\n",
    "    allptomop = pd.read_csv(odir_tf + 'patient_sentence_long.csv')\n",
    "    \n",
    "    try: \n",
    "        train_personid = np.load(options['train_personid_mintimefilt_file'])\n",
    "        test_personid = np.load(options['test_personid_mintimefilt_file'])\n",
    "    except: \n",
    "        raise Exception('Run 2_predictAD.ipynb first')\n",
    "    \n",
    "    print('train:',pts_train_tf.shape, train_personid.shape)\n",
    "    print('test:',pts_test_tf.shape, test_personid.shape)\n",
    "    \n",
    "    # Training data prep\n",
    "    if os.path.isfile(odir_tf + 'model_unmatched_input_data.joblib'):\n",
    "        print('loading in saved model inputs... ')\n",
    "        unmatched_model_inputs = joblib.load(odir_tf + 'model_unmatched_input_data.joblib')\n",
    "\n",
    "        X_train = unmatched_model_inputs['X_train']\n",
    "        X_test = unmatched_model_inputs['X_test']\n",
    "        feature_names = unmatched_model_inputs['feature_names']\n",
    "        varthresh = unmatched_model_inputs['varthresh']\n",
    "        y_train = unmatched_model_inputs['y_train']\n",
    "        y_test = unmatched_model_inputs['y_test']\n",
    "\n",
    "        print('variance thresholded n features:', varthresh.get_support(1).shape)\n",
    "        feature_names_var = feature_names[varthresh.get_support(1)]\n",
    "        feature_name_info = feature_names.to_frame('concept_id').rename_axis('')\\\n",
    "            .merge(omopdata.concepts.groupby('concept_id').head(1), \n",
    "                   on = 'concept_id', how = 'left').set_index('concept_id')\n",
    "        print('X_train shape: {}, X_test shape: {}'.format(X_train.shape, X_test.shape))\n",
    "        print('length of y_train: {}. \\n\\tsum of y_train: {}. \\n\\tmean of y_train: {:0.07f}'.format(\\\n",
    "                        len(y_train), y_train.sum(), y_train.mean()))\n",
    "        print('length of y_test: {}. \\n\\tsum of y_test: {}. \\n\\tmean of y_test: {:0.07f}'.format(\\\n",
    "                    len(y_test), y_test.sum(), y_test.mean()))\n",
    "    else: \n",
    "        raise Exception('Run 2_predictAD.ipynb first')\n",
    "        \n",
    "    ########\n",
    "    # Stratify by Sex\n",
    "    ########\n",
    "    person_id_train_F = np.intersect1d(allpt_tf.query(\"Sex == 'Female'\").index, person_id_train)\n",
    "    person_id_train_M = np.intersect1d(allpt_tf.query(\"Sex == 'Male'\").index, person_id_train)\n",
    "    print('train all: {}, train all F: {}, train all M: {}'.format(\\\n",
    "                person_id_train.shape, person_id_train_F.shape, person_id_train_M.shape))\n",
    "    person_id_test_F = np.intersect1d(allpt_tf.query(\"Sex == 'Female'\").index, person_id_test)\n",
    "    person_id_test_M = np.intersect1d(allpt_tf.query(\"Sex == 'Male'\").index, person_id_test)\n",
    "    print('test all: {}, test all F: {}, test all M: {}'.format(\\\n",
    "                person_id_test.shape, person_id_test_F.shape, person_id_test_M.shape))\n",
    "\n",
    "    train_personid_F = np.intersect1d(allpt_tf.query(\"Sex == 'Female'\").index, train_personid)\n",
    "    train_personid_M = np.intersect1d(allpt_tf.query(\"Sex == 'Male'\").index, train_personid)\n",
    "    print('train: {}, train F: {}, train M: {}'.format(train_personid.shape, train_personid_F.shape, train_personid_M.shape))\n",
    "    test_personid_F = np.intersect1d(allpt_tf.query(\"Sex == 'Female'\").index, test_personid)\n",
    "    test_personid_M = np.intersect1d(allpt_tf.query(\"Sex == 'Male'\").index, test_personid)\n",
    "    print('test: {}, test F: {}, test M: {}'.format(test_personid.shape, test_personid_F.shape, test_personid_M.shape))\n",
    "\n",
    "    # demographics of updated pts\n",
    "    print('train F:',person_id_train_F.shape, train_personid_F.shape)\n",
    "    print('test F:',person_id_test_F.shape, test_personid_F.shape)\n",
    "    display_table(allpt_tf.loc[np.concatenate((train_personid_F,test_personid_F))].reset_index(),  \n",
    "                  groupby = 'AD', options = options)\n",
    "\n",
    "    print('train M:',person_id_train_M.shape, train_personid_M.shape)\n",
    "    print('test M:',person_id_test_M.shape, test_personid_M.shape)\n",
    "    display_table(allpt_tf.loc[np.concatenate((train_personid_M,test_personid_M))].reset_index(),  \n",
    "                  groupby = 'AD', options = options)\n",
    "\n",
    "    ########\n",
    "    # get the input data (X) and the labels (y) for train and test. Apply variance threshold to X.\n",
    "    ########\n",
    "    # X\n",
    "    X_train_F = X_train.loc[train_personid_F]; X_train_M = X_train.loc[train_personid_M]\n",
    "    print('shape of X_train: {}, X_train_F: {}, X_train_M: {}'.format(X_train.shape, X_train_F.shape, X_train_M.shape))\n",
    "    varthresh_F = VarianceThreshold().fit(X_train_F); varthresh_M = VarianceThreshold().fit(X_train_M)\n",
    "    N_FEATURES_F = varthresh_F.get_support().sum(); N_FEATURES_M = varthresh_M.get_support().sum()\n",
    "    print('variance thresholded n features F:{}, M:{}'.format(varthresh_F.get_support(1).shape, varthresh_M.get_support(1).shape))\n",
    "    X_test_F = X_test.loc[test_personid_F]; X_test_M = X_test.loc[test_personid_M]\n",
    "    print('shape of X_test: {}, X_test_F: {}, X_test_M: {}'.format(X_test.shape, X_test_F.shape, X_test_M.shape))\n",
    "\n",
    "\n",
    "    # y\n",
    "    y_train_F = allpt_tf.loc[train_personid_F][dxgroup].to_numpy()\n",
    "    print('length of y_train_F: {}. \\n\\tsum of y_train_F: {}. \\n\\tmean of y_train_F: {:0.07f}'.format(\\\n",
    "                    len(y_train_F), y_train_F.sum(), y_train_F.mean()))\n",
    "    y_test_F = allpt_tf.loc[test_personid_F][dxgroup].to_numpy()\n",
    "    print('length of y_test_F: {}. \\n\\tsum of y_test_F: {}. \\n\\tmean of y_test_F: {:0.07f}'.format(\\\n",
    "                len(y_test_F), y_test_F.sum(), y_test_F.mean()))\n",
    "    y_train_M = allpt_tf.loc[train_personid_M][dxgroup].to_numpy()\n",
    "    print('length of y_train_F: {}. \\n\\tsum of y_train_M: {}. \\n\\tmean of y_train_M: {:0.07f}'.format(\\\n",
    "                    len(y_train_F), y_train_M.sum(), y_train_M.mean()))\n",
    "    y_test_M = allpt_tf.loc[test_personid_M][dxgroup].to_numpy()\n",
    "    print('length of y_test_M: {}. \\n\\tsum of y_test_M: {}. \\n\\tmean of y_test_M: {:0.07f}'.format(\\\n",
    "                len(y_test_M), y_test_M.sum(), y_test_M.mean()))\n",
    "\n",
    "    X_train_F2 = varthresh_F.transform(X_train_F); X_train_M2 = varthresh_M.transform(X_train_M)\n",
    "    feature_names_var_F = feature_names[varthresh_F.get_support(1)]; feature_names_var_M = feature_names[varthresh_M.get_support(1)]\n",
    "    X_test_F2 = X_test_F[feature_names_var_F].to_numpy(); X_test_M2 = X_test_M[feature_names_var_M].to_numpy();\n",
    "    \n",
    "    # prep output\n",
    "    odir_tf_f = odir_tf + 'Female/'\n",
    "    odir_tf_m = odir_tf + 'Male/'\n",
    "    os.makedirs(odir_tf_f, exist_ok = True); os.makedirs(odir_tf_m, exist_ok = True);\n",
    "    if 'odir_tf_strat' not in options:\n",
    "        options['odif_tf_strat'] = {'Female':odir_tf_f, 'Male':odir_tf_m}\n",
    "        save_updated_options(options)\n",
    "        \n",
    "    #######\n",
    "    # Random Forest\n",
    "    ######\n",
    "    # For FEMALES\n",
    "    np.random.seed(1100)\n",
    "    if os.path.isfile(odir_tf_f+'rf_unmatched_model.joblib'):\n",
    "        print('reading in saved model...')\n",
    "        rf_unmatched_dict_F = joblib.load(fname)\n",
    "        rf_feat_import_unmatched_F  = feature_context(rf_unmatched_dict_F['feat_import'], feature_name_info, \n",
    "                                         import_col = 'rf_import', modelkind = 'rf_unmatched')\n",
    "    else: \n",
    "        pt_choice_F = np.concatenate((np.where(y_train_F)[0], \n",
    "                        np.random.choice(np.where(1-y_train_F)[0], int(y_train_F.sum())*ratio)))\n",
    "        rf_unmatched_dict_F = rf_model(X_train_F2[pt_choice_F], y_train_F[pt_choice_F],\n",
    "                     X_test_F2, y_test_F, feature_names_var_F, options, odir_tf = odir_tf_f, modelsuffix = '_unmatched')\n",
    "        rf_feat_import_unmatched_F = feature_context(rf_unmatched_dict_F['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_unmatched', odir_tf = odir_tf_f)\n",
    "        \n",
    "    # for MAES\n",
    "    if os.path.isfile(odir_tf_m+'rf_unmatched_model.joblib'):\n",
    "        print('reading in saved model...')\n",
    "        rf_unmatched_dict_M = joblib.load(odir_tf_m+'rf_unmatched_model.joblib')\n",
    "        rf_feat_import_unmatched_M  = feature_context(rf_unmatched_dict_M['feat_import'], feature_name_info, \n",
    "                                         import_col = 'rf_import', modelkind = 'rf_unmatched')\n",
    "    else: \n",
    "        pt_choice_M = np.concatenate((np.where(y_train_M)[0], \n",
    "                        np.random.choice(np.where(1-y_train_M)[0], int(y_train_M.sum())*ratio)))\n",
    "        rf_unmatched_dict_M = rf_model(X_train_M2[pt_choice_M], y_train_M[pt_choice_M],\n",
    "                     X_test_M2, y_test_M, feature_names_var_M, options, odir_tf = odir_tf_m, modelsuffix = '_unmatched', do_gridsearch = False)\n",
    "        rf_feat_import_unmatched_M = feature_context(rf_unmatched_dict_M['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_unmatched', odir_tf = odir_tf_m)\n",
    "        \n",
    "    ######\n",
    "    # Match Patients Within Sex Strata\n",
    "    #####\n",
    "    from clinspokeprediction.match_fx import match_patients\n",
    "    cols_match_num = options['match_params']['cols_match_num'] + options['match_params']['cols_match_vis']\n",
    "    cols_match_cat = options['match_params']['cols_match_cat']\n",
    "\n",
    "    cohortpts_tf_train = allpt_tf_train[allpt_tf_train[dxgroup]==1].reset_index()\n",
    "    controlpts_tf_train = allpt_tf_train[allpt_tf_train[dxgroup]==0].reset_index()\n",
    "    print('TRAIN: \\ncohortpts shape (prior): {}\\ncontrolpts shape: {}'.format(cohortpts_tf_train.shape, controlpts_tf_train.shape))  \n",
    "    cohortpts_tf_test = allpt_tf_test[allpt_tf_test[dxgroup]==1].reset_index()\n",
    "    controlpts_tf_test = allpt_tf_test[allpt_tf_test[dxgroup]==0].reset_index()\n",
    "    print('TEST: \\ncohortpts shape (prior): {}\\ncontrolpts shape: {}'.format(cohortpts_tf_test.shape, controlpts_tf_test.shape))\n",
    "    \n",
    "    fname = odir_tf_f + 'cohort_control_pt_train_tf.joblib'\n",
    "    if os.path.isfile(fname):\n",
    "        print('loading in matched females...')\n",
    "        tt_temp = joblib.load(fname)\n",
    "        cohortpts_tf_train_F = tt_temp['cohortpts_tf_train']; controlpts_tf_train_F = tt_temp['controlpts_tf_train']\n",
    "        allpt_tf_matched_F = tt_temp['allpt_tf_matched']\n",
    "        del tt_temp\n",
    "    else: \n",
    "        cohortpts_tf_train_F = cohortpts_tf_train[cohortpts_tf_train.person_id.isin(train_personid_F)]\n",
    "        controlpts_tf_train_F = controlpts_tf_train[controlpts_tf_train.person_id.isin(train_personid_F)]\n",
    "        print('cohortpts_F shape: {}\\ncontrolpts_F shape: {}'.format(cohortpts_tf_train_F.shape, controlpts_tf_train_F.shape))\n",
    "        cohortpts_tf_train_F, controlpts_tf_train_F, _ = match_patients(cohortpts_tf_train_F, controlpts_tf_train_F, dxgroup, \n",
    "                        cols_match_cat = cols_match_cat, cols_match_num = cols_match_num, ratio = options['ratio'], return_split = True)\n",
    "        allpt_tf_matched_F = cohortpts_tf_train_F.append(controlpts_tf_train_F).set_index('person_id')\n",
    "        joblib.dump({'cohortpts_tf_train': cohortpts_tf_train_F, 'controlpts_tf_train': controlpts_tf_train_F, \n",
    "                     'allpt_tf_matched': allpt_tf_matched_F}, odir_tf_f + 'cohort_control_pt_train_tf.joblib')\n",
    "\n",
    "        mytable = TableOne(allpt_tf_matched_F, columns = cols_match_num + cols_match_cat, \n",
    "                       groupby=dxgroup, categorical = cols_match_cat, smd = True, pval = True);\n",
    "        display(mytable)\n",
    "        mytable.to_csv(odir_tf_f + 'allpt_train_tf_matched.csv')\n",
    "\n",
    "    fname = odir_tf_m + 'cohort_control_pt_train_tf.joblib'\n",
    "    if os.path.isfile(fname):\n",
    "        print('loading in matched males...')\n",
    "        tt_temp = joblib.load(fname)\n",
    "        cohortpts_tf_train_M = tt_temp['cohortpts_tf_train']; controlpts_tf_train_M = tt_temp['controlpts_tf_train']\n",
    "        allpt_tf_matched_M = tt_temp['allpt_tf_matched']\n",
    "        del tt_temp\n",
    "    else: \n",
    "        cohortpts_tf_train_M = cohortpts_tf_train[cohortpts_tf_train.person_id.isin(train_personid_M)]\n",
    "        controlpts_tf_train_M = controlpts_tf_train[controlpts_tf_train.person_id.isin(train_personid_M)]\n",
    "        print('cohortpts_M shape: {}\\ncontrolpts_M shape: {}'.format(cohortpts_tf_train_M.shape, controlpts_tf_train_M.shape))\n",
    "        cohortpts_tf_train_M, controlpts_tf_train_M, _ = match_patients(cohortpts_tf_train_M, controlpts_tf_train_M, dxgroup, \n",
    "                            cols_match_cat = cols_match_cat, cols_match_num = cols_match_num, ratio = options['ratio'], return_split = True)\n",
    "        allpt_tf_matched_M = cohortpts_tf_train_M.append(controlpts_tf_train_M).set_index('person_id')\n",
    "        joblib.dump({'cohortpts_tf_train': cohortpts_tf_train_M, 'controlpts_tf_train': controlpts_tf_train_M, \n",
    "                     'allpt_tf_matched': allpt_tf_matched_M}, odir_tf_m + 'cohort_control_pt_train_tf.joblib')\n",
    "\n",
    "        mytable = TableOne(allpt_tf_matched_M, columns = cols_match_num + cols_match_cat, \n",
    "                           groupby=dxgroup, categorical = cols_match_cat, smd = True, pval = True);\n",
    "        display(mytable)\n",
    "        mytable.to_csv(odir_tf_m + 'allpt_train_tf_matched.csv')\n",
    "        \n",
    "    # preprocess\n",
    "    if os.path.isfile(odir_tf_f + 'model_matched_input_data.joblib') and os.path.isfile(odir_tf_m + 'model_matched_input_data.joblib'):\n",
    "        print('loading in X/y females...')\n",
    "        tt_temp = joblib.load(odir_tf_f + 'model_matched_input_data.joblib')\n",
    "        train_personid_matched_F = tt_temp['train_personid_matched']; test_personid_matched_F = tt_temp['test_personid_matched']\n",
    "        X_train_F = tt_temp['X_train']; X_test_F = tt_temp['X_test']\n",
    "        y_train_F = tt_temp['y_train']; y_test_F = tt_temp['y_test']\n",
    "        varthresh_F = tt_temp['varthresh']; feature_names_var_F = feature_names[varthresh_F.get_support(1)]; \n",
    "\n",
    "        print('loading in X/y males...')\n",
    "        tt_temp = joblib.load(odir_tf_m + 'model_matched_input_data.joblib')\n",
    "        train_personid_matched_M = tt_temp['train_personid_matched']; test_personid_matched_M = tt_temp['test_personid_matched']\n",
    "        X_train_M = tt_temp['X_train']; X_test_M = tt_temp['X_test']\n",
    "        y_train_M = tt_temp['y_train']; y_test_M = tt_temp['y_test']\n",
    "        varthresh_M = tt_temp['varthresh']; feature_names_var_M = feature_names[varthresh_M.get_support(1)]\n",
    "        del tt_temp\n",
    "\n",
    "        N_FEATURES_F = varthresh_F.get_support().sum(); N_FEATURES_M = varthresh_M.get_support().sum()\n",
    "        X_train_F2 = varthresh_F.transform(X_train_F); X_train_M2 = varthresh_M.transform(X_train_M)\n",
    "        X_test_F2 = X_test_F[feature_names_var_F].to_numpy(); X_test_M2 = X_test_M[feature_names_var_M].to_numpy();\n",
    "        X_test_mF = X_test.loc[test_personid_matched_F, feature_names_var_F].fillna(0)\n",
    "        X_test_mM = X_test.loc[test_personid_matched_M, feature_names_var_M].fillna(0)\n",
    "        X_test_mF2 = X_test_mF.to_numpy(); X_test_mM2 = X_test_mM.to_numpy();\n",
    "    else: \n",
    "        ########\n",
    "        # X and y TRAIN MATCHED \n",
    "        ########\n",
    "        train_personid_matched_F = allpt_tf_matched_F.index; train_personid_matched_M = allpt_tf_matched_M.index\n",
    "        X_train_F = X_train.loc[train_personid_matched_F]; X_train_M = X_train.loc[train_personid_matched_M]\n",
    "        y_train_F = allpt_tf_matched_F[dxgroup].to_numpy(); y_train_M = allpt_tf_matched_M[dxgroup].to_numpy()\n",
    "        print('shape of X_train: {}, X_train_F: {}, X_train_M: {}'.format(X_train.shape, X_train_F.shape, X_train_M.shape))\n",
    "        print('len of y_train_F: {}, y_train_M: {}'.format(len(y_train_F), len(y_train_M)))\n",
    "\n",
    "        varthresh_F = VarianceThreshold().fit(X_train_F); varthresh_M = VarianceThreshold().fit(X_train_M)\n",
    "        print('variance thresholded n features F:{}, M:{}'.format(varthresh_F.get_support(1).shape, varthresh_M.get_support(1).shape))\n",
    "        feature_names_var_F = feature_names[varthresh_F.get_support(1)]; feature_names_var_M = feature_names[varthresh_M.get_support(1)]\n",
    "\n",
    "        N_FEATURES_F = varthresh_F.get_support().sum(); N_FEATURES_M = varthresh_M.get_support().sum()\n",
    "        X_train_F2 = varthresh_F.transform(X_train_F); X_train_M2 = varthresh_M.transform(X_train_M)\n",
    "\n",
    "        ########\n",
    "        # X and y TEST with new variance thresholds\n",
    "        ########\n",
    "        X_test_F = X_test.loc[test_personid_F]; X_test_M = X_test.loc[test_personid_M];\n",
    "        X_test_F2 = X_test_F[feature_names_var_F].to_numpy(); X_test_M2 = X_test_M[feature_names_var_M].to_numpy();\n",
    "        print('shape of X_test: {}, X_test_F: {}, X_test_M: {}'.format(X_test.shape, X_test_F2.shape, X_test_M2.shape))\n",
    "\n",
    "        test_personid_matched_F = allpt_tf_test_matched_F.index; test_personid_matched_M = allpt_tf_test_matched_M.index\n",
    "        X_test_mF = X_test.loc[test_personid_matched_F, feature_names_var_F].fillna(0)\n",
    "        X_test_mM = X_test.loc[test_personid_matched_M, feature_names_var_M].fillna(0)\n",
    "        X_test_mF2 = X_test_mF.to_numpy(); X_test_mM2 = X_test_mM.to_numpy();\n",
    "        print('shape of X_test_mF (matched): {}, X_test_mM (matched): {}'.format(X_test_mF.shape, X_test_mM.shape))\n",
    "\n",
    "        y_test_F = allpt_tf.loc[test_personid_F][dxgroup].to_numpy(); y_test_M = allpt_tf.loc[test_personid_M][dxgroup].to_numpy()\n",
    "        y_test_mF = allpt_tf_test_matched_F[dxgroup].to_numpy(); y_test_mM = allpt_tf_test_matched_M[dxgroup].to_numpy()\n",
    "\n",
    "        # save\n",
    "        joblib.dump({'X_train':X_train_F, 'X_test':X_test_F, 'y_train':y_train_F, 'y_test':y_test_F, 'feature_names':feature_names,\n",
    "                 'train_personid_matched':train_personid_matched_F,'test_personid_matched':test_personid_matched_F, 'varthresh':varthresh_F},\n",
    "                 odir_tf_f + 'model_matched_input_data.joblib')\n",
    "        joblib.dump({'X_train':X_train_M, 'X_test':X_test_M, 'y_train':y_train_M, 'y_test':y_test_M, 'feature_names':feature_names,\n",
    "                 'train_personid_matched':train_personid_matched_M,'test_personid_matched':test_personid_matched_M, 'varthresh':varthresh_M},\n",
    "                 odir_tf_m + 'model_matched_input_data.joblib')\n",
    "        \n",
    "    ### Random Forest Models\n",
    "    # FEMALES\n",
    "    if os.path.isfile(odir_tf_f+'rf_matched_model.joblib'):\n",
    "        print('reading in saved model...')\n",
    "        rf_matched_dict_F  = joblib.load(fname)\n",
    "        rf_feat_import_matched_F = feature_context(rf_matched_dict_F['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_matched')\n",
    "    else:  \n",
    "        rf_matched_dict_F = rf_model(X_train_F2, y_train_F,\n",
    "                     X_test_F2, y_test_F, feature_names_var_F, options, \n",
    "                     odir_tf = odir_tf_f, modelsuffix = '_matched',\n",
    "                     n_its = 30, do_gridsearch = False)\n",
    "        rf_feat_import_matched_F = feature_context(rf_matched_dict_F['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_matched', odir_tf = odir_tf_f)\n",
    "    rf_metrics2_F = analyze_clf(rf_matched_dict_F['model'], X_train_F2, X_test_mF2, \n",
    "                    y_train_F, y_test_mF, odir_tf_f+'rf_matched_testmatched', \n",
    "                    dxgroup, comparison, show_fig = True)\n",
    "    print(rf_metrics2_F)\n",
    "    \n",
    "    # MALES\n",
    "    if os.path.isfile(odir_tf_m+'rf_matched_model.joblib') and not redo:\n",
    "        print('reading in saved model...')\n",
    "        rf_matched_dict_M  = joblib.load(fname)\n",
    "        rf_feat_import_matched_M = feature_context(rf_matched_dict_M['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_matched')\n",
    "    else:  \n",
    "        rf_matched_dict_M = rf_model(X_train_M2, y_train_M,\n",
    "                     X_test_M2, y_test_M, feature_names_var_M, options, odir_tf = odir_tf_m, \n",
    "                     modelsuffix = '_matched', n_its = 30, do_gridsearch = False)\n",
    "        rf_feat_import_matched_M = feature_context(rf_matched_dict_M['feat_import'], feature_name_info, \n",
    "                            import_col = 'rf_import', modelkind = 'rf_matched', odir_tf = odir_tf_m)\n",
    "\n",
    "    rf_metrics2_M = analyze_clf(rf_matched_dict_M['model'], X_train_M2, X_test_mM2, \n",
    "                    y_train_M, y_test_mM, odir_tf_m+'rf_matched_testmatched', \n",
    "                    dxgroup, comparison, show_fig = True)\n",
    "    print(rf_metrics2_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_ehrml",
   "language": "python",
   "name": "dask_ehrml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
